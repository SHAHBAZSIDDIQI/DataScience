{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementation of Cyclic gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UF3Zh83xldq9soJzjxlZS5AvLyTJwNoF",
      "authorship_tag": "ABX9TyOIljuIZmWA+aTyMWgORF+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHAHBAZSIDDIQI/DataScience/blob/master/Generating%20dynamic%20image%20translation%20using%20Generative%20Adversarial%20Network%20Cyclic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRx6SD5s6D4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading important packages \n",
        "from random import random\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqaZ2GPaNZeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "#import tensorflow_addons as tfa     #for instanceNormalization\n",
        "#from tfa.layers import instancenormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxHRH2HsVjAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46b77b14-dfb0-4b7d-e591-2a110c8761c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhGMZzqWXXzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC7PMDxtQEuQ",
        "colab_type": "text"
      },
      "source": [
        "defining the discriminator, however the input will be 128x128 image and hence the motive is to implement the 70x70 patch gan that will narrow down the convolutions to 8*8 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-QfJdVZPP9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_discriminator(image_shape):\n",
        "  init = RandomNormal(stddev = 0.02)\n",
        "  in_image = Input(shape = image_shape)\n",
        "  d = Conv2D(64,(4,4),strides = (2,2),padding='same',kernel_initializer=init)(in_image)    #C64 converts 128x128 to 64x64\n",
        "  d = LeakyReLU(alpha = 0.2)(d)\n",
        "  \n",
        "  d= Conv2D(128,(4,4),strides = (2,2),padding='same',kernel_initializer=init)(d)   #c128 converts 64x64 to 32x32\n",
        "  d= InstanceNormalization(axis=-1)(d)\n",
        "  d= LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d= Conv2D(256,(4,4),strides = (2,2),padding='same',kernel_initializer=init)(d)   #C256 converts 32x32 to 16x16\n",
        "  d= InstanceNormalization(axis=-1)(d)\n",
        "  d= LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d= Conv2D(512,(4,4),strides = (2,2),padding='same',kernel_initializer=init)(d)   #C512 converts 16x16 to 8x8\n",
        "  d= InstanceNormalization(axis=-1)(d)\n",
        "  d= LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d= Conv2D(512,(4,4),padding='same',kernel_initializer=init)(d)   #second last layer\n",
        "  d= InstanceNormalization(axis=-1)(d)\n",
        "  d= LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  patch_out = Conv2D(1,(4,4),padding='same',kernel_initializer=init)(d)\n",
        "\n",
        "  model = Model(in_image,patch_out)\n",
        "  model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R9CXpBTVBo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = (128,128,3)\n",
        "model = define_discriminator(image_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znrSRrlfVQTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_block(n_filters,input_layer):\n",
        "  init = RandomNormal(stddev = 0.02)\n",
        "  g = Conv2D(n_filters,(3,3),padding='same',kernel_initializer=init)(input_layer)\n",
        "  g = InstanceNormalization(axis = -1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  g = Conv2D(n_filters,(3,3),padding='same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis = -1)(g)\n",
        "\n",
        "  g = Concatenate()([g, input_layer])   #the trick here merging happen, this is whr magic happens\n",
        "  return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqca7eb5b8Bp",
        "colab_type": "text"
      },
      "source": [
        "The generator will be 6 resnet since we are using 128x128 pixel input data. It will be Cnolution layer of single strides followed by strides 2 then resnets  followed by upscaling to same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En9f6nvIcfHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_generator(image_shape, n_resnet = 6):\n",
        "  init = RandomNormal(stddev = 0.02)\n",
        "  in_image = Input(shape=image_shape)\n",
        "\n",
        "  g = Conv2D(64,(7,7),padding = 'same',kernel_initializer=init)(in_image)\n",
        "  g = InstanceNormalization(axis = -1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  g = Conv2D(128,(3,3),strides = (2,2),padding = 'same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis=-1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  g = Conv2D(256,(3,3),strides = (2,2),padding = 'same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis=-1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  #Applying ResNet\n",
        "  for _ in range(n_resnet):\n",
        "    g = resnet_block(128,g)\n",
        "  \n",
        "  #upscaling\n",
        "\n",
        "  g = Conv2DTranspose(128,(3,3),strides=(2,2),padding = 'same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis = -1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  g = Conv2DTranspose(64,(3,3),strides = (2,2),padding='same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis=-1)(g)\n",
        "  g = Activation('relu')(g)\n",
        "\n",
        "  g = Conv2D(3,(7,7),padding = 'same',kernel_initializer=init)(g)\n",
        "  g = InstanceNormalization(axis=-1)(g)\n",
        "  \n",
        "  out_image  = Activation('tanh')(g)\n",
        "  model = Model(in_image,out_image)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2fqT3eycfZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing model architecture \n",
        "image_shape = (128,128,3)\n",
        "model = define_generator(image_shape)\n",
        "model.summary()     #reduced to 6 millions from 35 millions in 9 resnet of 256 filters each"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ylwtgq6cfbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_composite_model(g_model_1,d_model,g_model_2,image_shape):\n",
        "  g_model_1.trainable = True\n",
        "  d_model.trainable = False\n",
        "  g_model_2.trainable = False\n",
        "\n",
        "  input_gen= Input(shape = image_shape)\n",
        "  gen1_out = g_model_1(input_gen)\n",
        "  output_d = d_model(gen1_out)\n",
        "\n",
        "  input_id = Input(shape=image_shape)\n",
        "  output_id = g_model_1(input_id)\n",
        "\n",
        "  output_f = g_model_2(gen1_out)\n",
        "\n",
        "  gen2_out = g_model_2(input_id)\n",
        "  output_b = g_model_1(gen2_out)\n",
        "  \n",
        "  model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "  # define optimization algorithm configuration\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  # compile model with weighting of least squares loss and L1 loss\n",
        "  model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "  return model\n",
        "\n",
        " # model = Model([input_gen,input_id],[output_d,output_id,output_f,output_b])\n",
        " # opt = Adam(lr = 0.0002,beta_1 = 0.5)\n",
        " # model.compile(loss=['mse','mae','mae','mae'],loss_weight = [0.1,0.5,1,1],optimizer = opt)\n",
        "  #return model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTzOYkpjsp5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "  # load the dataset\n",
        "  data = load(filename)\n",
        "  # unpack arrays\n",
        "  X1, X2 = data['arr_0'], data['arr_1']\n",
        "  # scale from [0,255] to [-1,1]\n",
        "  X1 = (X1 - 127.5) / 127.5\n",
        "  X2 = (X2 - 127.5) / 127.5\n",
        "  return [X1, X2]\n",
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(dataset)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "\t# save the first generator model\n",
        "\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
        "\tg_model_AtoB.save(filename1)\n",
        "\t# save the second generator model\n",
        "\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
        "\tg_model_BtoA.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        " \n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "\t# select a sample of input images\n",
        "\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "\t# generate translated images\n",
        "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_in = (X_in + 1) / 2.0\n",
        "\tX_out = (X_out + 1) / 2.0\n",
        "\t# plot real images\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_in[i])\n",
        "\t# plot translated image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_out[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        " \n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "\tselected = list()\n",
        "\tfor image in images:\n",
        "\t\tif len(pool) < max_size:\n",
        "\t\t\t# stock the pool\n",
        "\t\t\tpool.append(image)\n",
        "\t\t\tselected.append(image)\n",
        "\t\telif random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "\t\t\tselected.append(image)\n",
        "\t\telse:\n",
        "\t\t\t# replace an existing image and use replaced image\n",
        "\t\t\tix = randint(0, len(pool))\n",
        "\t\t\tselected.append(pool[ix])\n",
        "\t\t\tpool[ix] = image\n",
        "\treturn asarray(selected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqI2xtE3cfej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(d_model_A,d_model_B,g_model_AtoB,g_modelBtoA,c_model_AtoB,c_model_BtoA, dataset):\n",
        "  n_epochs, n_batch = 5,1\n",
        "  n_patch = d_model_A.output_shape[1]\n",
        "  trainA, trainB = dataset['arr_0'],dataset['arr_1']\n",
        "  poolA,poolB = list(),list()\n",
        "  bat_per_epo = int(len(trainA) / n_batch)\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  for i in range(n_steps):\n",
        "    X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "    X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "    \n",
        "    X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "    X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "    \n",
        "    X_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "    X_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "    #updating generator B to A\n",
        "    g_loss2,_,_,_,_ = c_model_BtoA.train_on_batch([X_realB,X_realA],[y_realA,X_realA,X_realB,X_realA])\n",
        "\n",
        "    dA_loss1 = d_model_A.train_on_batch(X_realA,y_realA)\n",
        "    dA_loss2 = d_model_A.train_on_batch(X_fakeA,y_fakeA)\n",
        "\n",
        "    #updating generator A to B\n",
        "    g_loss1,_,_,_,_ = c_model_BtoA.train_on_batch([X_realA,X_realB],[y_realB,X_realB,X_realA,X_realB])\n",
        "\n",
        "    dB_loss1 = d_model_B.train_on_batch(X_realB,y_realB)\n",
        "    dB_loss2 = d_model_B.train_on_batch(X_fakeB,y_fakeB)\n",
        "\n",
        "    print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "    if (i+1) % (bat_per_epo * 1) == 0:\n",
        "      # plot A->B translation\n",
        "      summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
        "      # plot B->A translation\n",
        "      summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
        "    if (i+1) % (bat_per_epo * 5) == 0:\n",
        "      # save the models\n",
        "      save_models(i, g_model_AtoB, g_model_BtoA)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VptUli9ivyEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "data = load('/content/drive/My Drive/Colab Notebooks/horse2zebra_128.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN_jBEys4wk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data['arr_0'].shape[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkNpSEldtGmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = data['arr_0'].shape[1:]\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIssNJ8JzA0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"g_model_AtoB_005935.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iDPw3icE3tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"g_model_BtoA_005935.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmYUDpwZFGG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from numpy import load\n",
        "from numpy import vstack\n",
        "from matplotlib import pyplot\n",
        "from numpy.random import randint\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        " \n",
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "\t# load the dataset\n",
        "\tdata = load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        " \n",
        "# select a random sample of images from the dataset\n",
        "def select_sample(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\treturn X\n",
        " \n",
        "# plot the image, the translation, and the reconstruction\n",
        "def show_plot(imagesX, imagesY1, imagesY2):\n",
        "\timages = vstack((imagesX, imagesY1, imagesY2))\n",
        "\ttitles = ['Real', 'Generated', 'Reconstructed']\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\timages = (images + 1) / 2.0\n",
        "\t# plot images row by row\n",
        "\tfor i in range(len(images)):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(1, len(images), 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(images[i])\n",
        "\t\t# title\n",
        "\t\tpyplot.title(titles[i])\n",
        "\tpyplot.show()\n",
        " \n",
        "A_data, B_data = load_real_samples('/content/drive/My Drive/Colab Notebooks/horse2zebra_128.npz')\n",
        "print('Loaded', A_data.shape, B_data.shape)\n",
        "cust = {'InstanceNormalization': InstanceNormalization}\n",
        "model_AtoB = load_model('g_model_AtoB_005935.h5', cust,compile=False)\n",
        "model_BtoA = load_model('g_model_BtoA_005935.h5', cust,compile=False)\n",
        "A_real = select_sample(A_data, 1)\n",
        "B_generated  = model_AtoB.predict(A_real)\n",
        "A_reconstructed = model_BtoA.predict(B_generated)\n",
        "show_plot(A_real, B_generated, A_reconstructed)\n",
        "# plot B->A->B\n",
        "B_real = select_sample(B_data, 1)\n",
        "A_generated  = model_BtoA.predict(B_real)\n",
        "B_reconstructed = model_AtoB.predict(A_generated)\n",
        "show_plot(B_real, A_generated, B_reconstructed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnJO5zAzFtJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4f1bfd8e-eaea-4d5c-dddf-d9b9ad2b57f1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AtoB_generated_plot_001187.png\tBtoA_generated_plot_003561.png\n",
            "AtoB_generated_plot_002374.png\tBtoA_generated_plot_004748.png\n",
            "AtoB_generated_plot_003561.png\tBtoA_generated_plot_005935.png\n",
            "AtoB_generated_plot_004748.png\tdrive\n",
            "AtoB_generated_plot_005935.png\tg_model_AtoB_005935.h5\n",
            "BtoA_generated_plot_001187.png\tg_model_BtoA_005935.h5\n",
            "BtoA_generated_plot_002374.png\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbkOaBuBHGqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "im=load_img('AtoB_generated_plot_005935.png')\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiRen1FPHjY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im=load_img('BtoA_generated_plot_005935.png')\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ukhAngHq5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('AtoB_generated_plot_005935.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wmCDmJbH0gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}