{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Embedding generation and elaborated Evaluation_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUU5ZeUSY1PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The purpose of the notebook is to generate embedding using different pretrained bert model and evaluate them locally on the colab environment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ2hoy8Gef0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "nltk.download('popular')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elzcTQm6Yc1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "import random\n",
        "import string\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import spatial\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTzhsW7lYc6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert2lower(inputstr):\n",
        "    return inputstr.lower()\n",
        "\n",
        "def removeNum(inputstr):\n",
        "    return re.sub(r'\\d+','',inputstr)\n",
        "\n",
        "def removePunc(inputstr):\n",
        "    for x in inputstr.lower(): \n",
        "        if x in punctuations: \n",
        "            inputstr = inputstr.replace(x, \"\")\n",
        "    return inputstr\n",
        "\n",
        "def removeWhiteSpace(inputstr):\n",
        "    return inputstr.strip()\n",
        "\n",
        "def removeStopWordsandLemmatize(inputstr):\n",
        "    token = word_tokenize(inputstr)\n",
        "    result = [i for i in token if not i in stop_words]\n",
        "    result = [lemmatizer.lemmatize(i) for i in result]\n",
        "    return ' '.join(result)\n",
        "\n",
        "def CompletePreprocessingofWord(tweet):\n",
        "    if(tweet == ''):\n",
        "      return tweet\n",
        "    clean_tweet = convert2lower(tweet)\n",
        "    clean_tweet = removeNum(clean_tweet)\n",
        "    clean_tweet = removePunc(clean_tweet)\n",
        "    clean_tweet = removeStopWordsandLemmatize(clean_tweet)\n",
        "    clean_tweet = removeWhiteSpace(clean_tweet)\n",
        "    return clean_tweet\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8KSTH6bYdAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def getuniquehashtags(tweetlist):\n",
        "        allhashtags = []\n",
        "        for tweet in tweetlist:\n",
        "            allhashtags.extend(re.findall(r\"#(\\w+)\",str(tweet)))\n",
        "        return list(set(allhashtags))\n",
        "    \n",
        "    def getUniqueMentionedUsers(tweetlist):\n",
        "        allmentionedUser = []\n",
        "        for tweet in tweetlist:\n",
        "            allmentionedUser.extend(re.findall(r\"@(\\w+)\",str(tweet)))\n",
        "        return list(set(allmentionedUser))\n",
        "    \n",
        "    def getAllhashtags(tweetlist):\n",
        "        allhashtags = []\n",
        "        for tweet in tweetlist:\n",
        "            allhashtags.extend(re.findall(r\"#(\\w+)\",str(tweet)))\n",
        "        return allhashtags\n",
        "    \n",
        "    def getAllMentionedUsers(tweetlist):\n",
        "        allmentionedUser = []\n",
        "        for tweet in tweetlist:\n",
        "            allmentionedUser.extend(re.findall(r\"@(\\w+)\",str(tweet)))\n",
        "        return allmentionedUser\n",
        "    \n",
        "    def RemoveTags(tweet):\n",
        "      tweet = re.sub('@','at ',str(tweet))    #[^\\s]+\n",
        "      tweet = re.sub('#','',str(tweet))     #[^\\s]+\n",
        "      tweet = re.sub('RT','',str(tweet))\n",
        "      return tweet  \n",
        "    \n",
        "    def RemoveMentionedUserAndHashTags(tweet):\n",
        "      tweet = re.sub('@[^\\s]+','',str(tweet))    #[^\\s]+\n",
        "      tweet = re.sub('#[^\\s]+','',str(tweet))     #[^\\s]+\n",
        "      tweet = re.sub('RT','',str(tweet))\n",
        "      return tweet \n",
        "\n",
        "    def RemoveHTTP(tweet):\n",
        "      clean_tweet = re.match('(.*?)http.*?\\s?(.*?)',str(tweet))\n",
        "      if(clean_tweet):\n",
        "        return clean_tweet.group(1)\n",
        "      else:\n",
        "        return tweet\n",
        "\n",
        "    def RemoveHttps(tweet):\n",
        "        clean_tweet = re.match('(.*?)https.*?\\s?(.*?)',str(tweet))\n",
        "        if(clean_tweet):\n",
        "          return clean_tweet.group(1)\n",
        "        else:\n",
        "          return tweet\n",
        "\n",
        "    def RemoveWWW(tweetlist):\n",
        "        l = []\n",
        "        for tweet in tweetlist:    \n",
        "            clean_tweet = re.match('(.*?)www.*?\\s?(.*?)',str(tweet))\n",
        "            if(clean_tweet):\n",
        "                l.append(clean_tweet.group(1))\n",
        "            else:\n",
        "                l.append(tweet)\n",
        "            #l.append(re.sub(r\"http:\\+\",\"\",str(tweet)))\n",
        "        return l\n",
        "    \n",
        "    def DeEmojify(tweet):\n",
        "        #print(tweet)\n",
        "        if(tweet == ''):\n",
        "          return tweet\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        \n",
        "        tweet.encode('ascii', 'ignore').decode('ascii')\n",
        "        return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr0XDWZGYc9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/MainDF.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT_4byUF8334",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df = Main_df[[\"AUTHOR_ID\",\"TRANS_AUTHOR_BIO\",\"Account Type\",\"Snippet\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dfvi7848_pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ51KBbU9CDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########Cleaning the text#####################\n",
        "for _,x in Main_df.iterrows():\n",
        "  x[\"TRANS_AUTHOR_BIO\"] = RemoveTags(x[\"TRANS_AUTHOR_BIO\"])\n",
        "  x[\"TRANS_AUTHOR_BIO\"] = DeEmojify(x[\"TRANS_AUTHOR_BIO\"])\n",
        "  x[\"TRANS_AUTHOR_BIO\"] = CompletePreprocessingofWord(x[\"TRANS_AUTHOR_BIO\"])    #removeAbb   must remove in case you want to drag org separately "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF8z7YiJ-03q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### Cleaning the tweets##################\n",
        "for _,x in Main_df.iterrows():\n",
        "  x['Snippet'] = RemoveTags(x['Snippet'])\n",
        "  x['Snippet'] = RemoveHTTP(x['Snippet'])\n",
        "  x['Snippet'] = RemoveHttps(x['Snippet'])\n",
        "  x['Snippet'] = DeEmojify(x['Snippet'])\n",
        "  x['Snippet'] = CompletePreprocessingofWord(x['Snippet'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XBwDKs4ArZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############Using Sentence BioBERT model to embed user individual column embedding #################\n",
        "\n",
        "!pip install biobert-embedding==0.1.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnRrRzedGUlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from biobert_embedding.embedding import BiobertEmbedding\n",
        "biobert_model = BiobertEmbedding()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2mvGUmDOLze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df['SnippetEmbedding'] = \"\"\n",
        "Main_df['Autho_Info_Embedding'] = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCu3sI3sVjNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df = Main_df.head(4280)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiC5EaBhIdTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "for _,x in Main_df.iterrows():\n",
        "  x['SnippetEmbedding'] = np.asarray(biobert_model.sentence_vector(x['Snippet']))\n",
        "  x['Autho_Info_Embedding'] = np.asarray(biobert_model.sentence_vector(x['TRANS_AUTHOR_BIO']))\n",
        "  count = count + 1\n",
        "  print(\"epoch --\" + str(count) + \" / 4280\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP19Mulo4XNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqQbFMb2SF9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df.to_csv('/content/drive/My Drive/Colab Notebooks/BioBertEmbedd_DF.csv', header=True, index=False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjzJk60sG4Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################Build AutoEncoder to reduce dimension#######################\n",
        "####AutoEncoder1 to reduce 1536 dimension to 300 dimensions -- since we have to concatenate 2 embeddings together #######\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Dropout,Flatten,Input\n",
        "from keras.layers import BatchNormalization,Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import mean_squared_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5u3Ay85W4ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_df = Main_df.tail(3000)\n",
        "type(train_data_df['SnippetEmbedding'][1280])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj21rh8aLM_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---- Creating Training Data-----\n",
        "train_data_df = Main_df.tail(3000)\n",
        "TotalMatrix = []\n",
        "TotalMatrix = np.concatenate((TotalMatrix,train_data_df['SnippetEmbedding'][1280]), axis=None)\n",
        "TotalMatrix = np.concatenate((TotalMatrix,train_data_df['Autho_Info_Embedding'][1280]), axis=None)\n",
        "#-- test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5IULQubX1bg",
        "colab_type": "code",
        "outputId": "71e3e018-ee7d-4ec4-c77a-847208c59909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TotalMatrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3001, 1536)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAUIhxTELNCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _,x in train_data_df.iterrows():\n",
        "  vec = []\n",
        "  vec = np.concatenate((vec,x['SnippetEmbedding']), axis=None)\n",
        "  vec = np.concatenate((vec,x['Autho_Info_Embedding']), axis=None)\n",
        "  TotalMatrix = np.vstack((TotalMatrix,vec))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW_-tW7CLNGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(TotalMatrix)\n",
        "training_data, test_data = TotalMatrix[:2500,:],TotalMatrix[2500:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1ATkJ1iYhhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_dims = 300\n",
        "input_dim = Input(shape = (1536,))\n",
        "encoded = Dense(encoding_dims, activation='relu')(input_dim)\n",
        "decoded = Dense(1536, activation='tanh')(encoded)\n",
        "autoencoder = Model(input_dim,decoded)\n",
        "\n",
        "encoder = Model(input_dim,encoded)\n",
        "\n",
        "encoded_input = Input(shape=(encoding_dims,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "autoencoder.compile(optimizer='adadelta', loss=mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnt8Wr2nYvDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.fit(training_data, training_data,\n",
        "                epochs=1000,\n",
        "                batch_size=250,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_data, test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD1spa6UY3SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "decoder.save('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_decoder.model')\n",
        "autoencoder.save('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_autoencoder.h5')\n",
        "encoder.save('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_encoder.h5')\n",
        "encoder.save('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_encoder.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bIFbU5F3bi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "encoder = load_model('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_encoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zA2ZMTzahVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df['Combined_Embedding'] = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9t5WhF6anSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "for _,x in Main_df.iterrows():\n",
        "  vec = []\n",
        "  vec = np.concatenate((vec,x['SnippetEmbedding']), axis=None)\n",
        "  vec = np.concatenate((vec,x['Autho_Info_Embedding']), axis=None)\n",
        "  mat = []\n",
        "  mat = np.vstack((vec,vec))\n",
        "  emb = encoder.predict(mat)\n",
        "  x['Combined_Embedding'] = emb[0]\n",
        "  count = count + 1\n",
        "  print(\"epoch --\" + str(count) + \" / 4280\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa9ZJcE_daWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/TrainData_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWB7AXTG_auG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc3lLjl7GSoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _,x in train_df.iterrows():\n",
        "  rowd = Main_df.loc[Main_df['AUTHOR_ID'] == x['AUTHOR_ID']]\n",
        "  ind = rowd.index.values.astype(int)[0]\n",
        "  emb = Main_df.iloc[ind]['Combined_Embedding']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PczfxwK48kCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TransferEmbedding(authorid):\n",
        "  emb = np.zeros(300)\n",
        "  rowd = Main_df.loc[Main_df['AUTHOR_ID'] == authorid]\n",
        "  if(rowd.shape[0] > 0):\n",
        "    ind = rowd.index.values.astype(int)[0]\n",
        "    emb = Main_df.iloc[ind]['Combined_Embedding']\n",
        "  return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8YcrBx9Mw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'] = [TransferEmbedding(x['AUTHOR_ID']) for _,x in train_df.iterrows()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcNI2_rUHP9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Main_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_vUCPp4_Bb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################Testing the Classification ######################\n",
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "category5 = []\n",
        "category6 = []\n",
        "category7 = []\n",
        "category8 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category5.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category6.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category7.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category8.append(trow['Embedding'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAqVb0t1IREM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(category1[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRtS0sdcHbhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import spatial\n",
        "def measureSimilarityMeanofUser(userEmb,category):\n",
        "    sumsc = 0\n",
        "    for user in category:\n",
        "        res = 1 - spatial.distance.cosine(user,userEmb)\n",
        "        sumsc = sumsc + res\n",
        "    \n",
        "    mean = sumsc / len(category)\n",
        "    return mean\n",
        "    \n",
        "def getlabelforUser(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category5))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category6))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category7))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category8))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ_L-dUiHfNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce0cOM8aJlrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)\n",
        "category5 = customSplit(category5,5)\n",
        "category6 = customSplit(category6,6)\n",
        "category7 = customSplit(category7,7)\n",
        "category8 = customSplit(category8,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaCG80TNSzch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(labelList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gci8RZ1hS28l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(TestDataList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyJsNTYMKIWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########Evaluations############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EAszGABKxjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction = correct_prediction + 1\n",
        "\n",
        "correct_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17uX2PyBLm9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################ Reducing Bin to Nurse/ Doctors / organisation / Others #################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDvrDHFNA2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category2.append(trow['Embedding'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu8zEn_WNVLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getlabelforUser(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AN33AiaNjCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1hFY33XNp3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qle89mbQNu9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(labelList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvV_QRxYN0aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction = correct_prediction + 1\n",
        "\n",
        "correct_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyRbCO1PN_Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########Save the matrix #########################\n",
        "MAT = []\n",
        "MAT = Main_df['Combined_Embedding'][0]\n",
        "for _,x in Main_df.iterrows():\n",
        "  MAT = np.vstack((MAT,x['Combined_Embedding']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJJ55L1PIV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileName = '/content/drive/My Drive/Colab Notebooks/BioBERT_Combined_AutoEnc_Emb_Matrix.txt'\n",
        "np.savetxt(fileName,MAT,fmt='%.8f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhyNv13dPLdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################Testing for Full Embedding #####################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-vnFa_QZOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MultiColumnTransferEmbedding(authorid):\n",
        "  vec = []\n",
        "  rowd = Main_df.loc[Main_df['AUTHOR_ID'] == authorid]\n",
        "  if(rowd.shape[0] > 0):\n",
        "    ind = rowd.index.values.astype(int)[0]\n",
        "    emb1 = Main_df.iloc[ind]['SnippetEmbedding']\n",
        "    emb2 = Main_df.iloc[ind]['Autho_Info_Embedding']\n",
        "    vec = np.concatenate((vec,emb1),axis=None)\n",
        "    vec = np.concatenate((vec,emb2),axis=None)\n",
        "  if(len(vec) == 0):\n",
        "    return np.zeros(1536)\n",
        "  else:\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOT1tjNmQ191",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'] = [MultiColumnTransferEmbedding(x['AUTHOR_ID']) for _,x in train_df.iterrows()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hMnqKyURuH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'][0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNfBCbk3R1jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################Bio Clinical-BERT Evaluation #################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjtMw3yiUONT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H8qI5feUBzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk8zKUx7VgwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-ZERnxtUB46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GenerateEmbClinicalBERT(text):\n",
        "  input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
        "  output = model(input_ids)\n",
        "  d1 = output[0].mean(1).detach().numpy()\n",
        "  return d1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNOhCbd1UB3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF = Main_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzW2p5GIWKXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clinical_DF['SnippetEmbedding'] = [GenerateEmbClinicalBERT(x['Snippet']) for _,x in Clinical_DF.iterrows()]\n",
        "count = 1\n",
        "for _,x in Clinical_DF.iterrows():\n",
        "  x['SnippetEmbedding'] = GenerateEmbClinicalBERT(x['Snippet'])\n",
        "  x['Autho_Info_Embedding'] = GenerateEmbClinicalBERT(x['TRANS_AUTHOR_BIO'])\n",
        "  print(\"epoch  \" + str(count) + \" / 6000\")\n",
        "  count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoKQEnAWM_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF = Clinical_DF.head(4280)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWU_XZUsEX9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF['Combined_Embedding'] = \"\"          #Adding a new column to reduce the dimension of the two combined embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_65iurPlKLU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8TZ6uNKPPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "encoder = load_model('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_encoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLUIVnr8KX6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReduceLargerEmbedding_toCombined(DataFrm):\n",
        "  count = 0\n",
        "  for _,x in DataFrm.iterrows():\n",
        "    vec = []\n",
        "    vec = np.concatenate((vec,x['SnippetEmbedding']), axis=None)\n",
        "    vec = np.concatenate((vec,x['Autho_Info_Embedding']), axis=None)\n",
        "    mat = []\n",
        "    mat = np.vstack((vec,vec))\n",
        "    emb = encoder.predict(mat)\n",
        "    x['Combined_Embedding'] = emb[0]\n",
        "    count = count + 1\n",
        "    print(\"epoch --\" + str(count) + \" / 4280\")\n",
        "  return DataFrm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYbN5EsQLnNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF = ReduceLargerEmbedding_toCombined(Clinical_DF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDlBITxL2Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clinical_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjq7u5KiL7rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####----- Evaluation of Embedding ------#########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5sTCX6DOmPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/TrainData_1.csv')\n",
        "train_df = train_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaPGEWr8OmS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TransferEmbedding(authorid,DataFrm):\n",
        "  emb = np.zeros(300)\n",
        "  rowd = DataFrm.loc[DataFrm['AUTHOR_ID'] == authorid]\n",
        "  if(rowd.shape[0] > 0):\n",
        "    ind = rowd.index.values.astype(int)[0]\n",
        "    emb = DataFrm.iloc[ind]['Combined_Embedding']\n",
        "  else:\n",
        "    print('zero')\n",
        "  return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mguMc7nTOmWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'] = [TransferEmbedding(x['AUTHOR_ID'],Clinical_DF) for _,x in train_df.iterrows()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7GbHkLl7Q5OW",
        "colab": {}
      },
      "source": [
        "###################Testing the Classification ######################\n",
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "category5 = []\n",
        "category6 = []\n",
        "category7 = []\n",
        "category8 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category5.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category6.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category7.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category8.append(trow['Embedding'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kL-R0mbBRokk",
        "colab": {}
      },
      "source": [
        "from scipy import spatial\n",
        "def measureSimilarityMeanofUser(userEmb,category):\n",
        "    sumsc = 0\n",
        "    for user in category:\n",
        "        res = 1 - spatial.distance.cosine(user,userEmb)\n",
        "        sumsc = sumsc + res\n",
        "    \n",
        "    mean = sumsc / len(category)\n",
        "    return mean\n",
        "    \n",
        "def getlabelforUser_8(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category5))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category6))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category7))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category8))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cumCF4eFRokq",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-yT5vq9Roku",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)\n",
        "category5 = customSplit(category5,5)\n",
        "category6 = customSplit(category6,6)\n",
        "category7 = customSplit(category7,7)\n",
        "category8 = customSplit(category8,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgIOwcEeSHgt",
        "colab_type": "code",
        "outputId": "a03ca507-b702-47d8-f1b1-f8a2eef81376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(TestDataList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06-mFsdkRsPS",
        "colab_type": "code",
        "outputId": "13d71ac7-5f56-4dd6-fd3e-df10dde0c93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_prediction_combined_8 = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser_8(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction_combined_8 = correct_prediction_combined_8 + 1\n",
        "\n",
        "correct_prediction_combined_8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JnMThGpSgcM",
        "colab": {}
      },
      "source": [
        "################ Reducing Bin to 4 #################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y2T7-IkNSgcO",
        "colab": {}
      },
      "source": [
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category2.append(trow['Embedding'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b_OmdsycSgcQ",
        "colab": {}
      },
      "source": [
        "def getlabelforUser_4(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_DJq0yixSgcT",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vrwFChNGSgcY",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVWDuoiRS2Xz",
        "outputId": "64404a5f-a69e-46a3-edc7-b09f5f46eea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_prediction_combined_4 = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser_4(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction_combined_4 = correct_prediction_combined_4 + 1\n",
        "\n",
        "correct_prediction_combined_4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDFuKxijS-za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(TestDataList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NqoSU4dcW63M",
        "colab": {}
      },
      "source": [
        "def MultiColumnTransferEmbedding(authorid,DataFrm):\n",
        "  vec = []\n",
        "  rowd = DataFrm.loc[DataFrm['AUTHOR_ID'] == authorid]\n",
        "  if(rowd.shape[0] > 0):\n",
        "    ind = rowd.index.values.astype(int)[0]\n",
        "    emb1 = DataFrm.iloc[ind]['SnippetEmbedding']\n",
        "    emb2 = DataFrm.iloc[ind]['Autho_Info_Embedding']\n",
        "    vec = np.concatenate((vec,emb1),axis=None)\n",
        "    vec = np.concatenate((vec,emb2),axis=None)\n",
        "  if(len(vec) == 0):\n",
        "    return np.zeros(1536)\n",
        "  else:\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bjD5guDW63P",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'] = [MultiColumnTransferEmbedding(x['AUTHOR_ID'],SciBERT_DF) for _,x in train_df.iterrows()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rTDVNouYJZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'][0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rf76j3eGb2UG",
        "colab": {}
      },
      "source": [
        "###################Testing the Classification ######################\n",
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "category5 = []\n",
        "category6 = []\n",
        "category7 = []\n",
        "category8 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category5.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category6.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category7.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category8.append(trow['Embedding'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LzQ8TryXb2UK",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qset70H8b2UM",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)\n",
        "category5 = customSplit(category5,5)\n",
        "category6 = customSplit(category6,6)\n",
        "category7 = customSplit(category7,7)\n",
        "category8 = customSplit(category8,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apg4Qc1_b2UQ",
        "outputId": "7c3a9705-34a9-4129-f1ff-85442da16d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_prediction_All_8 = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction_All_8 = correct_prediction_All_8 + 1\n",
        "\n",
        "correct_prediction_All_8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jak7Kezwb2US",
        "colab": {}
      },
      "source": [
        "category1 = []\n",
        "category2 = []\n",
        "category3 = []\n",
        "category4 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 1.0):\n",
        "    category1.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 2.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 3.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 4.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category4.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 6.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 7.0):\n",
        "    category3.append(trow['Embedding'])\n",
        "  if(trow['Label'] == 8.0):\n",
        "    category2.append(trow['Embedding'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eg_EeoDQb2UU",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AXwPK7ab2UW",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)\n",
        "category3 = customSplit(category3,3)\n",
        "category4 = customSplit(category4,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_bZC8LEb2UY",
        "outputId": "a29182dc-036f-4b64-92e0-a1088805e824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_prediction_All_4 = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction_All_4 = correct_prediction_All_4 + 1\n",
        "\n",
        "correct_prediction_All_4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlvO5VLcYsCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################Saving the Matrix for further evaluations later ##############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbjSkhYAdJtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SciBERT_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "poVjOqD8cyW3",
        "colab": {}
      },
      "source": [
        "#Change the column one by one and change it\n",
        "MAT = []\n",
        "MAT = Clinical_DF['Autho_Info_Embedding'][0]\n",
        "for _,x in Clinical_DF.iterrows():\n",
        "  MAT = np.vstack((MAT,x['Autho_Info_Embedding']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgcztJnqdtR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAT.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bY6e_ihRcyXG",
        "colab": {}
      },
      "source": [
        "fileName = '/content/drive/My Drive/Colab Notebooks/ClinalBERT_Autho_Info_Embedding_Matrix.txt'\n",
        "np.savetxt(fileName,MAT,fmt='%.8f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KfxZcWvac_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################## SCI BERT ########################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vPf-l81qeiu-",
        "colab": {}
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tOEuG_XPeivD",
        "colab": {}
      },
      "source": [
        "def GenerateEmbSCiBERT(text):\n",
        "  input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
        "  output = model(input_ids)\n",
        "  d1 = output[0].mean(1).detach().numpy()\n",
        "  return d1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZ2gTRXVeivF",
        "colab": {}
      },
      "source": [
        "SciBERT_DF = Main_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YyTUi5qheivH",
        "colab": {}
      },
      "source": [
        "#Clinical_DF['SnippetEmbedding'] = [GenerateEmbClinicalBERT(x['Snippet']) for _,x in Clinical_DF.iterrows()]\n",
        "count = 1\n",
        "for _,x in SciBERT_DF.iterrows():\n",
        "  x['SnippetEmbedding'] = GenerateEmbSCiBERT(x['Snippet'])\n",
        "  x['Autho_Info_Embedding'] = GenerateEmbSCiBERT(x['TRANS_AUTHOR_BIO'])\n",
        "  print(\"epoch  \" + str(count) + \" / 6000\")\n",
        "  count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ohuA9WjeivJ",
        "colab": {}
      },
      "source": [
        "SciBERT_DF = SciBERT_DF.head(4280)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMkC87Z6eivL",
        "colab": {}
      },
      "source": [
        "SciBERT_DF['Combined_Embedding'] = \"\"          #Adding a new column to reduce the dimension of the two combined embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ub1G02tGeivP",
        "colab": {}
      },
      "source": [
        "SciBERT_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oPz_-QB0eivR",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "encoder = load_model('/content/drive/My Drive/Colab Notebooks/BERT_1536to300_encoder.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9w_ZuBdkeivS",
        "colab": {}
      },
      "source": [
        "def ReduceLargerEmbedding_toCombined(DataFrm):\n",
        "  count = 0\n",
        "  for _,x in DataFrm.iterrows():\n",
        "    vec = []\n",
        "    vec = np.concatenate((vec,x['SnippetEmbedding']), axis=None)\n",
        "    vec = np.concatenate((vec,x['Autho_Info_Embedding']), axis=None)\n",
        "    mat = []\n",
        "    mat = np.vstack((vec,vec))\n",
        "    emb = encoder.predict(mat)\n",
        "    x['Combined_Embedding'] = emb[0]\n",
        "    count = count + 1\n",
        "    print(\"epoch --\" + str(count) + \" / 4280\")\n",
        "  return DataFrm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PG6bhrkyeivU",
        "colab": {}
      },
      "source": [
        "SciBERT_DF = ReduceLargerEmbedding_toCombined(SciBERT_DF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cliN6BcceivW",
        "colab": {}
      },
      "source": [
        "SciBERT_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C2sViIyCeivY",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/TrainData_1.csv')\n",
        "train_df = train_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oR0CFDOyeivZ",
        "colab": {}
      },
      "source": [
        "def TransferEmbedding(authorid,DataFrm):\n",
        "  emb = np.zeros(300)\n",
        "  rowd = DataFrm.loc[DataFrm['AUTHOR_ID'] == authorid]\n",
        "  if(rowd.shape[0] > 0):\n",
        "    ind = rowd.index.values.astype(int)[0]\n",
        "    emb = DataFrm.iloc[ind]['Combined_Embedding']\n",
        "  else:\n",
        "    print('zero')\n",
        "  return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9i_mLe1eivc",
        "colab": {}
      },
      "source": [
        "train_df['Embedding'] = [TransferEmbedding(x['AUTHOR_ID'],SciBERT_DF) for _,x in train_df.iterrows()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg_xLK4gl-wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########Rest all the process for evaluation run as same as above ##### Make changes accordingly#################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UjsjJHqLoxTe",
        "colab": {}
      },
      "source": [
        "SciBERT_DF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NsIejhtNoxTi",
        "colab": {}
      },
      "source": [
        "#Change the column one by one and change it\n",
        "MAT = []\n",
        "MAT = SciBERT_DF['Combined_Embedding'][0]\n",
        "for _,x in SciBERT_DF.iterrows():\n",
        "  MAT = np.vstack((MAT,x['Combined_Embedding']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zNYD8eEOoxTk",
        "outputId": "969e671e-6125-4733-afcf-1a922257b144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAT.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4281, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ryV8I2ZtoxTm",
        "colab": {}
      },
      "source": [
        "fileName = '/content/drive/My Drive/Colab Notebooks/SciBERT_Combined_Embedding_Matrix.txt'\n",
        "np.savetxt(fileName,MAT,fmt='%.8f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvG69CTsmCZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################Classifying only on two categories HCP and Others ######################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo2oO6dYtIbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category1 = []\n",
        "category2 = []\n",
        "\n",
        "for _,trow in train_df.iterrows():\n",
        "  if(trow['Label'] == 5.0):\n",
        "    category2.append(trow['Embedding'])\n",
        "  else:\n",
        "    category1.append(trow['Embedding'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrrCdh1otIfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelList = []\n",
        "TestDataList = []\n",
        "\n",
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx5ayXD3tIY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getlabelforUser_2(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    #listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    #listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_CzMpOwGeq",
        "colab_type": "code",
        "outputId": "a4494096-9dea-48a8-e311-5b95ca3f209d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(TestDataList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAY_vK1etIWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category1 = customSplit(category1,1)\n",
        "category2 = customSplit(category2,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v24qbtqwvG69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction_All_2 = 0\n",
        "for i in range(len(TestDataList)):\n",
        "  correct_label = labelList[i]\n",
        "  prediction = getlabelforUser_2(TestDataList[i])\n",
        "  if(correct_label == prediction):\n",
        "    correct_prediction_All_2 = correct_prediction_All_2 + 1\n",
        "\n",
        "correct_prediction_All_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxUB78qx5vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################### Creating Final Printing of Evaluations #############################\n",
        "###########################################################################################################\n",
        "###########################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QwmbC-zvyHwH",
        "colab": {}
      },
      "source": [
        "def getlabelforUser_4(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ApBd2eEDyHwL",
        "colab": {}
      },
      "source": [
        "def getlabelforUser_2(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    #listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    #listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qcgwdAHfx6dt",
        "colab": {}
      },
      "source": [
        "from scipy import spatial\n",
        "def measureSimilarityMeanofUser(userEmb,category):\n",
        "    sumsc = 0\n",
        "    for user in category:\n",
        "        res = 1 - spatial.distance.cosine(user,userEmb)\n",
        "        sumsc = sumsc + res\n",
        "    \n",
        "    mean = sumsc / len(category)\n",
        "    return mean\n",
        "    \n",
        "def getlabelforUser_8(userEmb):\n",
        "    listScoreUser = []\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category1))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category2))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category3))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category4))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category5))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category6))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category7))\n",
        "    listScoreUser.append(measureSimilarityMeanofUser(userEmb,category8))\n",
        "    \n",
        "    m =  max(listScoreUser)\n",
        "    \n",
        "    return (listScoreUser.index(m) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYVSGqYynhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customSplit(userEmList,label):\n",
        "  n = len(userEmList) - 10\n",
        "  for i in range(n):\n",
        "    labelList.append(label)\n",
        "  TestDataList.extend(userEmList[10:])\n",
        "  return userEmList[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHwK2S50wOvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResult_AllEvaluation(train_df):\n",
        "  #Starting 8 bin categorisation and Evaluation \n",
        "  category1 = []\n",
        "  category2 = []\n",
        "  category3 = []\n",
        "  category4 = []\n",
        "  category5 = []\n",
        "  category6 = []\n",
        "  category7 = []\n",
        "  category8 = []\n",
        "\n",
        "  for _,trow in train_df.iterrows():\n",
        "    if(trow['Label'] == 1.0):\n",
        "      category1.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 2.0):\n",
        "      category2.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 3.0):\n",
        "      category3.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 4.0):\n",
        "      category4.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 5.0):\n",
        "      category5.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 6.0):\n",
        "      category6.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 7.0):\n",
        "      category7.append(trow['Embedding'])\n",
        "    if(trow['Label'] == 8.0):\n",
        "      category8.append(trow['Embedding'])\n",
        "\n",
        "  labelList = []\n",
        "  TestDataList = []\n",
        "  category1 = customSplit(category1,1)\n",
        "  category2 = customSplit(category2,2)\n",
        "  category3 = customSplit(category3,3)\n",
        "  category4 = customSplit(category4,4)\n",
        "  category5 = customSplit(category5,5)\n",
        "  category6 = customSplit(category6,6)\n",
        "  category7 = customSplit(category7,7)\n",
        "  category8 = customSplit(category8,8)\n",
        "\n",
        "  correct_prediction_All_8 = 0\n",
        "  for i in range(len(TestDataList)):\n",
        "    correct_label = labelList[i]\n",
        "    prediction = getlabelforUser(TestDataList[i])\n",
        "    if(correct_label == prediction):\n",
        "      correct_prediction_All_8 = correct_prediction_All_8 + 1\n",
        "\n",
        "  print(\"Prediction for Embedding Classification when classifying 8 categories\")\n",
        "  print(\"correct classification = \" + str(correct_prediction_All_8) + \" / \" + len(TestDataList) + \" Mean : \" + str(correct_prediction_All_8 / len(TestDataList)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}